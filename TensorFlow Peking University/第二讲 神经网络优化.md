# 第二讲 神经网络优化

[TOC]

## 本讲目标

学会神经网络优化过程，使用正则化减少过拟合，使用优化器更新网络参数。



## 章节目录

- 预备知识
- 神经网络复杂度
- 指数衰减学习率
- 激活函数
- 损失函数
- 欠拟合与过拟合
- 正则化减少过拟合
- 优化器更新网络参数



## 预备知识

#### `tf.where()`

```python
# tf.where(条件语句, 真返回A, 假返回B)

a = tf.constant([1,2,3,1,1])
b = tf.constant([0,1,3,4,5])
c = tf.where(tf.greater(a,b),a,b)
```



#### `np.random.RandomState.rand()`

```python
# np.random.RandomState.rand(维度)

import numpy as np
rdm = np.random.RandomState(seed=1)

# 返回一个随机标量
a = rdm.rand()
# 返回维度为2行3列随机数矩阵
b = rdm.rand(2,3)
```



#### `np.vstack()`

```python
# 将两个数组按垂直方向叠加
# np.vstack(数组1, 数组2)

import numpy as np
a = np.array([1,2,3])
b = np.array([4,5,6])
c = np.vstack((a,b))
```



#### `np.mgrid[] / .ravel[]  / np.c_[]`

```python
# 返回网格坐标点

# np.mgrid[起始值：结束值：步长，起始值：结束值：步长，...]

# x.ravel() 将x变为一维数组

# np.c_[数组1，数组2，...] 使返回的间隔数值点配对 

import numpy as np
x, y = np.mgrid[1:3:1, 2:4:0.5]
grid = np.c_[x.ravel(), y.ravel()]
print("x", x)
print("y", y)
print("grid:\n", grid)
```



## 神经网络（NN）复杂度

